VERBOSE: False
BASE_TASK_CONFIG_PATH: configs/tasks/rearrange/rearrange_easy.yaml
TRAINER_NAME: "transformer"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: ['disk']
TENSORBOARD_DIR: "tb"
VIDEO_DIR: "video_dir/rearrange_easy_test"
VIDEO_FPS: 30
VIDEO_RENDER_TOP_DOWN: False
VIDEO_RENDER_ALL_INFO: True
VIDEO_RENDER_VIEWS:
  - "THIRD_RGB_SENSOR"
SENSORS: ["HEAD_DEPTH_SENSOR"]
TEST_EPISODE_COUNT: -1
EVAL_CKPT_PATH_DIR: "data/ckpts/rearrange_easy_test"
NUM_ENVIRONMENTS: 1
WRITER_TYPE: 'wb'
# Visual sensors to include
CHECKPOINT_FOLDER: "data/ckpts/rearrange_easy_test"
NUM_UPDATES: -1
TOTAL_NUM_STEPS: 1.0e8
LOG_INTERVAL: 1
NUM_CHECKPOINTS: -1
CHECKPOINT_INTERVAL: 30
FORCE_TORCH_SINGLE_THREADED: True
EVAL_KEYS_TO_INCLUDE_IN_NAME: ['success'] #'reward', 'force', 
EVAL:
  SPLIT: "eval"
  USE_CKPT_CONFIG: True

RL:

  preemption:
    save_resume_state_interval: 20
  POLICY:
      name: "TransformerResNetPolicy"
      action_distribution_type: "mixed"
      ACTION_DIST:
        discrete_arm: true
        discrete_base: true
        use_std_param: true
        temperature: 1.0
      use_rgb: false
      offline: true
      include_visual_keys: ["robot_head_depth"] # "robot_head_depth", robot_head_rgb
      train_planner: false
      train_control: true
      temperature: 1.0
      

  REWARD_MEASURE: "composite_reward" #move_obj_reward
  SUCCESS_MEASURE: "composite_success"
  SUCCESS_REWARD: 100.0
  SLACK_REWARD: -0.01

  TRAJECTORY_DATASET:
    # trajectory_dir: "/srv/share/xhuang394/share_demos/rearrange"
    trajectory_dir: "/srv/share/xhuang394/share_demos/rearrange_easy"
    files_per_load: 1
    queue_size: 1


    steps_to_reload: 5000
    trajs_per_file: 10


  TRANSFORMER:
    lr: 1.0E-5
    eps: 1.0E-5
    grad_norm_clip: 0.5
    use_linear_lr_decay: True
    batch_size: 50
    num_workers: 2




    return_to_go: 100
    context_length: 30
    max_episode_step: 500
    # model_type: "reward_conditioned"
    model_type: "bc"
    n_head: 8
    n_layer: 6
    freeze_layer: [] #
    reg_flags: 
      outer_dropout: true
      outer_layernorm: true
      attention_dropout: true
      attention_layernorm: true
      feedforward_dropout: true
      feedforward_layernorm: true
    hidden_size: 512
    backbone: resnet18
    hidden_size: 512

    # Use double buffered sampling, typically helps
    # when environment time is similar or large than
    # policy inference time during rollout generation
    use_double_buffered_sampler: False

    sync_frac: 0.6
    # The PyTorch distributed backend to use
    distrib_backend: NCCL
    # Visual encoder backbone
    pretrained_weights: "data/ckpts/npnp_25k_seq_offline/ckpt.1.pth" #
    # Initialize with pretrained weights
    pretrained: False
    # Initialize just the visual encoder backbone with pretrained weights
    pretrained_encoder: False
    # Whether or not the visual encoder backbone will be trained.
    train_encoder: True

    # Model parameters
    backbone: resnet18 # resnet18

  

WB:
  PROJECT_NAME: "p-skill-transformer"
  ENTITY: "cvmlp-whoknowsss"
  RUN_NAME: "only_planner"
  GROUP: "trfm_easy_test"